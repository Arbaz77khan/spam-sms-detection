


import numpy as np 
import pandas as pd 





spam_df = pd.read_csv('spam.csv', encoding='latin-1')





spam_df


spam_df.shape


spam_df.sample(10)





# checking if last three columns contains any information or not
spam_df.info()


# As majority of data is missing in last three columns, we will drop these.
spam_df.drop(columns=['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'], inplace=True)
spam_df.sample(5)


# Renaming the columns
spam_df.rename(columns= {'v1': 'target', 'v2' : 'text'}, inplace = True)
spam_df.sample()


# Assigning values in target column

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()



spam_df['target'] = encoder.fit_transform(spam_df['target'])
spam_df.head()


# checking missing values
spam_df.isnull().sum()


# checking duplicate values
spam_df.duplicated().sum()


# As there are 403 duplicates, we will drop duplicate rows
spam_df = spam_df.drop_duplicates()


# checking duplicate values
spam_df.duplicated().sum()


spam_df.shape





spam_df.head(10)


# checking the counts of ham and spam rows
spam_df['target'].value_counts()


# for better representation, below graphical view
import matplotlib.pyplot as plt 
plt.pie(spam_df['target'].value_counts(), labels=['ham', 'spam'], autopct="%0.2f")
plt.show()


# Important note: Data is imbalance


# checking how many letters, words and sentence in target column


# Importing Natural Language Toolkit
import nltk


nltk.download('punkt')


nltk.download('punkt_tab')


spam_df.loc[:, 'num_characters'] = spam_df['text'].apply(len)


spam_df.head()


# num of words
spam_df.loc[:, 'num_words'] = spam_df['text'].apply(lambda x: len(nltk.word_tokenize(x)))


spam_df.head()


# num of sentence
spam_df.loc[:, 'num_sentence'] = spam_df['text'].apply(lambda x: len(nltk.sent_tokenize(x)))


spam_df.head()


# Analysis the newly added columns
spam_df[['num_characters', 'num_words', 'num_sentence']].describe()


# Analysis ham and spam seperatly
# for ham
spam_df[spam_df['target']==0][['num_characters', 'num_words', 'num_sentence']].describe()


# for spam
spam_df[spam_df['target']==1][['num_characters', 'num_words', 'num_sentence']].describe()


# Analysis through graph
import seaborn as sns
plt.figure(figsize=(12,6))
sns.histplot(spam_df[spam_df['target']==0]['num_characters'])
sns.histplot(spam_df[spam_df['target']==1]['num_characters'], color='red')


plt.figure(figsize=(12,6))
sns.histplot(spam_df[spam_df['target']==0]['num_words'])
sns.histplot(spam_df[spam_df['target']==1]['num_words'], color='red')


plt.figure(figsize=(12,6))
sns.histplot(spam_df[spam_df['target']==0]['num_sentence'])
sns.histplot(spam_df[spam_df['target']==1]['num_sentence'], color='red')


sns.pairplot(spam_df, hue = 'target')


spam_df.head()


spam_df[['target', 'num_characters', 'num_words', 'num_sentence']].corr()


sns.heatmap(spam_df[['target', 'num_characters', 'num_words', 'num_sentence']].corr(), annot = True)


# from above analysis we cam to know about below two points
# 1. we can inference that the spam sms are larger than ham sms.
# 2. There is a multicolliearity between newly added columns. So, we need to take only 1 column out of 3.
# We will proceed with num_characters column here and removing other two.


# from above analysis we cam to know about below two points
# 1. we can inference that the spam sms are larger than ham sms.
# 2. There is a multicolliearity between newly added columns. So, we need to take only 1 column out of 3.
# We will proceed with num_characters column here and removing other two.

































